<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Thinking Machines 的文章 - 人工智能文摘</title>
  <link rel="stylesheet" href="/style.css?v=1761783314007">
  <!-- KaTeX CSS for math rendering -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
</head>
<body>
  <header>
    <div class="container">
      <div class="header-content">
        <a href="/" class="site-title">人工智能文摘</a>
        <nav>
          <ul>
            <li><a href="/">首页</a></li>
            <li><a href="/author/paulgraham.html">Paul Graham</a></li>
            <li><a href="/author/karpathy.html">Andrej Karpathy</a></li>
            <li><a href="/author/thinkingmachines.html">Thinking Machines</a></li>
          </ul>
        </nav>
      </div>
    </div>
  </header>

  <main>
    
  <div class="container">
    <a href="/" class="back-link">← 返回首页</a>

    <div class="page-header">
      <h1 class="page-title">Thinking Machines</h1>
      <p class="page-subtitle">共 5 篇文章</p>
    </div>

    <div class="posts-grid">
      
    <a href="/post/thinkingmachines/2025-10-27-on-policy-distillation.html" class="post-card">
      <div class="post-meta">
        <span class="post-author">Thinking Machines Lab</span>
        <span class="post-date">2025年10月27日</span>
      </div>
      <h3 class="post-title">同策略蒸馏</h3>
      <p class="post-excerpt">LLM 在聚焦领域可以达到专家级表现，这源于多种能力的层层叠加：对输入的感知、知识检索、方案选择以及可靠执行。要实现这些，需要一套分层的训练方法，我们可以粗分为三个阶段： 预训练（Pre-training）：教授语言使用、广泛推理...</p>
    </a>
    <a href="/post/thinkingmachines/2025-10-01-announcing-tinker.html" class="post-card">
      <div class="post-meta">
        <span class="post-author">Thinking Machines Lab</span>
        <span class="post-date">2025年10月1日</span>
      </div>
      <h3 class="post-title">宣布推出 Tinker</h3>
      <p class="post-excerpt">TinkerToy 计算机 由 Daniel Hillis 和 Brian Silverman 发明 今天，我们发布了 Tinker，这是一套用于微调语言模型的灵活 API。它通过让研究者和黑客掌控算法与数据，赋能他们开展模型实验，而我们来处理分布式训练的复杂...</p>
    </a>
    <a href="/post/thinkingmachines/2025-09-29-lora.html" class="post-card">
      <div class="post-meta">
        <span class="post-author">Thinking Machines Lab</span>
        <span class="post-date">2025年9月29日</span>
      </div>
      <h3 class="post-title">无悔的 LoRA</h3>
      <p class="post-excerpt">当今最先进的语言模型包含多达数万亿个参数，使用数十万亿个标记进行预训练。基础模型的性能随着规模持续提升，因为这些万亿级参数对于学习和表征人类书面知识中的各种模式是必要的。 相比之下，后训练通常使用更小的数据...</p>
    </a>
    <a href="/post/thinkingmachines/2025-09-26-modular-manifolds.html" class="post-card">
      <div class="post-meta">
        <span class="post-author">Thinking Machines Lab</span>
        <span class="post-date">2025年9月26日</span>
      </div>
      <h3 class="post-title">模块化流形</h3>
      <p class="post-excerpt">当我们训练大型神经网络时，需要让它们保持“健康”。我们不希望网络中的张量——无论是权重、激活还是梯度——变得过大或过小。过小和过大的张量会带来各种问题，并不只限于数值下溢与上溢。例如，训练过程中权重矩阵的尺度变化会...</p>
    </a>
    <a href="/post/thinkingmachines/2025-09-10-defeating-nondeterminism-in-llm-inference.html" class="post-card">
      <div class="post-meta">
        <span class="post-author">Thinking Machines Lab</span>
        <span class="post-date">2025年9月10日</span>
      </div>
      <h3 class="post-title">击败 LLM 推理中的非确定性</h3>
      <p class="post-excerpt">可复现性是科学进步的基石。然而，要让大语言模型（LLM）给出可复现的结果却出奇地困难。 例如，你可能会发现多次向 ChatGPT 提同一个问题会得到不同的答案。这本身并不奇怪，因为从语言模型获取结果涉及“采样”：把模型输出转...</p>
    </a>
    </div>
  </div>
  </main>

  <footer>
    <div class="container">
      <p>&copy; 2025 人工智能文摘 - 精选 AI 领域优质文章</p>
    </div>
  </footer>
</body>
</html>