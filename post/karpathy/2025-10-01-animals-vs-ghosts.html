<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-L21J1MSBQH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-L21J1MSBQH');
  </script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- 基本 SEO -->
  <title>动物 vs 幽灵 - 人工智能文摘</title>
  <meta name="description" content="【Andrej Karpathy 文章中文翻译】终于有机会把这期 Sutton 做客 Dwarkesh 的节目 听完了，挺有意思也挺好玩。 作为背景，Sutton 的“The Bitter Lesson（苦涩教训）”在前沿 LLM 圈子里几乎成了“圣经”。研究者常常讨论、追问某个方法或想法是否“足够吃到苦涩教...">
  <meta name="keywords" content="Andrej Karpathy,AI,人工智能,机器学习,动物 vs 幽灵,中文翻译">
  <meta name="author" content="Andrej Karpathy">

  <!-- 规范链接 -->
  <link rel="canonical" href="https://digest.qcngt.com/post/karpathy/2025-10-01-animals-vs-ghosts.html">

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
  <link rel="shortcut icon" href="/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <meta name="apple-mobile-web-app-title" content="人工智能文摘" />
  <link rel="manifest" href="/site.webmanifest" />

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://digest.qcngt.com/post/karpathy/2025-10-01-animals-vs-ghosts.html">
  <meta property="og:title" content="动物 vs 幽灵 - 人工智能文摘">
  <meta property="og:description" content="【Andrej Karpathy 文章中文翻译】终于有机会把这期 Sutton 做客 Dwarkesh 的节目 听完了，挺有意思也挺好玩。 作为背景，Sutton 的“The Bitter Lesson（苦涩教训）”在前沿 LLM 圈子里几乎成了“圣经”。研究者常常讨论、追问某个方法或想法是否“足够吃到苦涩教...">
  <meta property="og:image" content="https://digest.qcngt.com/logo.png">
  <meta property="og:site_name" content="人工智能文摘">
  <meta property="og:locale" content="zh_CN">
  <meta property="article:published_time" content="2025-10-01T00:00:00.000Z">
  <meta property="article:modified_time" content="2025-10-01T00:00:00.000Z">
  <meta property="article:author" content="Andrej Karpathy">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:url" content="https://digest.qcngt.com/post/karpathy/2025-10-01-animals-vs-ghosts.html">
  <meta name="twitter:title" content="动物 vs 幽灵 - 人工智能文摘">
  <meta name="twitter:description" content="【Andrej Karpathy 文章中文翻译】终于有机会把这期 Sutton 做客 Dwarkesh 的节目 听完了，挺有意思也挺好玩。 作为背景，Sutton 的“The Bitter Lesson（苦涩教训）”在前沿 LLM 圈子里几乎成了“圣经”。研究者常常讨论、追问某个方法或想法是否“足够吃到苦涩教...">
  <meta name="twitter:image" content="https://digest.qcngt.com/logo.png">

  <!-- 样式和脚本 -->
  <link rel="stylesheet" href="/style.css?v=1761792928403">
  <!-- KaTeX CSS for math rendering -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
</head>
<body>
  <header>
    <div class="container">
      <div class="header-content">
        <a href="/" class="site-title">人工智能文摘</a>
        <nav>
          <button class="menu-toggle" aria-label="切换菜单">☰</button>
          <ul>
            <li><a href="/author/paulgraham.html">Paul Graham</a></li>
            <li><a href="/author/karpathy.html">Andrej Karpathy</a></li>
            <li><a href="/author/thinkingmachines.html">Thinking Machines</a></li>
          </ul>
        </nav>
      </div>
    </div>
  </header>

  <main>
    
  <div class="container">
    <article class="author-0">
      <div class="article-content">
        <div class="article-header">
          <h1 class="article-title">动物 vs 幽灵</h1>
          <div class="article-meta">
            
            <span class="article-original-title" title="原文标题">Animals vs Ghosts</span>
            <span>|</span>
            
            <span>Andrej Karpathy</span>
            <span>|</span>
            <span>2025-10-01</span>
          </div>
        </div>

        <p>终于有机会把这期 <a href="https://www.youtube.com/watch?v=21EYKqUsPfg">Sutton 做客 Dwarkesh 的节目</a> 听完了，挺有意思也挺好玩。</p>
<p>作为背景，Sutton 的“<a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter Lesson（苦涩教训）</a>”在前沿 LLM 圈子里几乎成了“圣经”。研究者常常讨论、追问某个方法或想法是否“足够吃到苦涩教训的红利”（也就是是否被安排成能随着算力增加自动受益），把它作为判断是否可行、是否值得追的代理指标。潜在的前提是：LLM 当然是高度“苦涩教训化”的——看看 LLM 的扩展定律吧，把算力放到横轴，指标就一路向右上。所以看到写下这篇文章的 Sutton 其实并不确定 LLM 是否“苦涩教训化”，这就颇为有趣。LLM 的训练数据是巨大的人类数据集，它既 1）由人类生成，又 2）是有限的。用完了怎么办？如何避免人类偏置？于是就出现了这样一个场景：以“苦涩教训”为圭臬的 LLM 研究者，被“苦涩教训”的作者本人当面质疑——有点狠。</p>
<p>某种意义上，Dwarkesh（在节目中代表 LLM 研究者的视角）与 Sutton 有些“各说各话”，因为 Sutton 心里有一套完全不同的架构，而 LLM 打破了其中很多原则。他自称“古典主义者”，并援引图灵的最初设想——打造一台“儿童机器”：一个能够通过与世界的动态交互，从经验中学习的系统。这里没有模仿互联网页面的巨型预训练阶段；也没有有监督微调。他指出这在动物王国是缺席的（这是个微妙但正确的点：动物当然会观察示范，但它们的动作并不会被其他动物直接强制/“遥操作”）。他还强调，即便你把预训练只当作在强化学习前的先验初始化，Sutton 也会认为这条路线带着人类偏置，路线本身就有些“跑偏”，有点像 AlphaZero（从未见过人类对局）击败 AlphaGo（由人类对局初始化）。在 Sutton 的世界观中，一切都来自通过强化学习与世界交互；奖励函数一部分由环境决定，也有一部分是内在动机，比如“乐趣”“好奇”，以及与你的世界模型预测质量相关的信号。并且智能体在测试时默认持续学习，而不是训练一次、此后只负责部署。总体上，Sutton 更关心我们与动物王国的共性，而非差异。“如果我们理解了一只松鼠，我们就差不多完成了。”</p>
<p>至于我的看法……</p>
<p>首先，我觉得 Sutton 是这个节目的绝佳嘉宾，我也喜欢 AI 领域仍保持思维的熵，并非人人都在沿着 LLM 的下一个局部迭代去“剥削”。AI 的主导范式已经发生过太多次离散跃迁，不能丢掉这种多样性。我也认为他对 LLM 并非苦涩教训化的批评并不失当。如今的前沿 LLM 是高度复杂的人工产物，每个阶段都渗透着大量“人味”——基础（预训练数据）是人类文本，微调数据是人类且经过筛选，强化学习的环境混合也由工程师调制。我们并没有一个真正、单一、干净、真正符合苦涩教训的“转动手柄就行”的算法，能被释放到世界里，仅凭经验就自动学会一切。</p>
<p>那样的算法到底是否存在？找到它当然会是一次巨大的 AI 突破。常见有两类“示例性证据”用来说明其可能性。第一个是 AlphaZero 的成功：完全从零开始、无需任何人类监督地学会下围棋。但围棋显然是一个简单、封闭的环境，你很难把这种设定类比到纷繁复杂的现实世界。我爱围棋，但在算法与范畴上，它本质上只是更难版本的井字棋。第二个例子是动物，比如松鼠。这里我个人也犹疑这是否合适，因为动物是经由与我们工业界可用条件完全不同的计算过程、不同的约束而产生的。动物的大脑在出生时远不是看上去的白板。首先，大量通常被归为“学习”的现象，在我看来更多是“发育成熟”。其次，即便那些显然属于“学习”的部分、而非发育，也更像是在某个强大的、已存在的基座上做“微调”。举例：斑马幼崽出生后几十分钟内就能在草原上奔跑、跟随它的母亲。这是一个高度复杂的感觉-运动任务，我无论如何都不认为这是从零开始、白板起步就能实现的。动物的大脑及其数十亿参数，拥有强大的初始化，这些都被编码在 DNA 的 ATCG 里，并在进化过程中通过“外环”优化而成。如果小斑马像强化学习那样，以随机抽搐的肌肉动作作为初始策略，它根本走不远。同理，我们的 AI 现在也有拥有数十亿参数的神经网络。这些参数需要丰富、高信息密度的监督信号。我们不可能重跑一遍进化。但我们拥有巨量的互联网文档。是的，这基本上就是动物界几乎不存在的监督学习。但它是一个务实的方式，能为数十亿参数积累足够多的软约束，从而不至于从零起步。总结：预训练是我们“简陋版的进化”。它是冷启动问题的一个候选解，之后再在更“正确”的任务上进行微调，例如在强化学习框架内——这也正是当下最前沿的 LLM 实验室普遍在做的事。</p>
<p>我仍然认为，从动物身上汲取灵感是值得的。我觉得 LLM 代理在算法上漏掉了不少强有力的点子，而这些仍能从动物智能中移植借鉴。我也仍然认为“苦涩教训”是对的，但在现实世界、就实操而言，我更把它当作一个值得追求（未必要抵达）的柏拉图式目标。对这两点，我都抱有两位数百分比的不确定性，并为那些不同意、尤其是在“苦涩教训”上更雄心勃勃的人们的工作喝彩。</p>
<p>所以，这把我们带回到当下的处境。直白地说，当今最前沿的 LLM 研究并不是在造“动物”，而是在召唤“幽灵”。你可以把“幽灵”看作可能智能空间里的一类截然不同的点。它们混杂了人性，被彻底地工程化过。它们是不完美的复制品，是对人类文档的一种统计蒸馏，再撒上一点点别的东西。它们并非柏拉图意义上的“苦涩教训化”，但也许是“务实意义上”的——至少相较于此前的很多东西。对我来说，看起来有可能随着时间推移，我们可以把这些幽灵沿着“动物”的方向越调越近；这未必是根本上的不相容，更可能是智能空间里“初始化”的问题。但也完全可能它们进一步分道扬镳，最终永久地不同、非“动物范”，却依然极其有用、并真正改造世界。或许 幽灵:动物 :: 飞机:鸟。</p>
<p>总之、概括且面向行动地说，我觉得这期节目是 Sutton 对前沿 LLM 研究者的一次扎实“真心话”。我们可能在“开发-利用”的档位上拧得有点过头。或许我们仍然不够“苦涩教训化”，而在铺台子、拼基准之外，很可能还有更强的想法与范式值得探索。动物或许是很好的灵感来源：内在动机、乐趣、好奇、赋能、多智能体自博弈、文化。尽情发挥你的想象力。</p>
<ul>
<li>亦可作为<a href="https://x.com/karpathy/status/1973435013875314729">这条推文</a>查看，方便回复/评论。</li>
<li>亦可作为<a href="https://chatgpt.com/share/68dd6833-67c4-8007-8f37-331eb5bd9ee0">ChatGPT 对话</a>查看，若你想分叉这段对话并在完整上下文（播客文字稿、“苦涩教训”文章，以及本文）下提问。</li>
</ul>
<h3>附录</h3>
<ul>
<li>我同意 Sutton 的看法：动物并不做有监督学习。我知道这是个容易让人困惑的微妙点。动物会观察示范，但严格来说并不会像监督学习那样被直接用动作“监督”；训练时没有谁会“遥操作”动物。我能想到最接近的情形是，例如你帮孩子用勺子吃饭，真的握着他们的手演示动作。即便那样，他们的大脑是不是真在“用这个信号训练”，也未可知；它可能仍然更准确地归为“观察”。无论如何，这些情况总体上非常罕见；而对 LLM 来说，预训练和 SFT 的默认学习模式恰恰是监督学习。也许换个说法更贴切：在 LLM 世界里，人类的做法类比为：给定这道数学题以及一份人类的示例解答，请解题；答对奖励 1 分。这不是 SFT，而是 RL。</li>
<li>Dwarkesh 简要指出：LLM 在测试时也有自己的持续学习，只是它不是基于权重训练的。我觉得 Sutton 没完全回应到这一点。上下文学习是一种测试时自适应的形式，例如这就是少样本提示有效的原因。最近也有大量工作关注“记忆”（比如 CLAUDE.md 文件），把文本/上下文作为载体来做测试时学习，而不是改动权重。</li>
<li>Dwarkesh 提到超长地平线的稀疏奖励（例如打造一家成功的初创公司）该如何奏效。Sutton 给出的答案是时序差分学习，本质上是未来奖励折扣。但我并不觉得这特别有说服力。我之前写过一些想法，我认为这里发生的是别的东西，而且在我看来它并不是强化学习。</li>
<li>节目里关于“梯度下降不会让你很好地泛化”等话题有不少讨论，我没有完全跟上。</li>
<li>有人指出幽灵很吓人。不一定，看看我小时候最喜欢的《<a href="https://en.wikipedia.org/wiki/Casper_the_Friendly_Ghost">卡斯柏</a>》。</li>
</ul>

        
        <div class="original-link">
          <a href="https://karpathy.bearblog.dev/animals-vs-ghosts/" target="_blank" rel="noopener noreferrer">
            查看原文 →
          </a>
        </div>
      </div>
    </article>

    <!-- Schema.org 结构化数据 -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "动物 vs 幽灵",
  "author": {
    "@type": "Person",
    "name": "Andrej Karpathy"
  },
  "datePublished": "2025-10-01T00:00:00.000Z",
  "dateModified": "2025-10-01T00:00:00.000Z",
  "description": "终于有机会把这期 Sutton 做客 Dwarkesh 的节目 听完了，挺有意思也挺好玩。 作为背景，Sutton 的“The Bitter Lesson（苦涩教训）”在前沿 LLM 圈子里几乎成了“圣经”。研究者常常讨论、追问某个方法或想法是否“足够吃到苦涩教...",
  "publisher": {
    "@type": "Organization",
    "name": "人工智能文摘",
    "logo": {
      "@type": "ImageObject",
      "url": "https://digest.qcngt.com/logo.png"
    }
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://digest.qcngt.com/post/karpathy/2025-10-01-animals-vs-ghosts.html"
  }
}
    </script>
  </div>
  </main>

  <footer>
    <div class="container">
      <p>&copy; 2025 人工智能文摘 - 精选 AI 领域优质文章中文翻译</p>
      <p>版权归原文作者所有，仅供学习交流 | 联系方式: <a href="mailto:nblintao+digest@gmail.com">nblintao+digest@gmail.com</a></p>
    </div>
  </footer>

  <script>
    // 汉堡菜单切换
    document.addEventListener('DOMContentLoaded', function() {
      const menuToggle = document.querySelector('.menu-toggle');
      const navMenu = document.querySelector('nav ul');

      if (menuToggle && navMenu) {
        menuToggle.addEventListener('click', function(e) {
          e.stopPropagation();
          navMenu.classList.toggle('active');
        });

        // 点击页面其他地方关闭菜单
        document.addEventListener('click', function(e) {
          if (!e.target.closest('nav')) {
            navMenu.classList.remove('active');
          }
        });

        // 点击菜单项后关闭菜单
        navMenu.querySelectorAll('a').forEach(function(link) {
          link.addEventListener('click', function() {
            navMenu.classList.remove('active');
          });
        });
      }
    });
  </script>
</body>
</html>